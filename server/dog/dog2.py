import os
import torch
import multiprocessing
import sqlite3
import datetime
from pathlib import Path
from torch import nn
from PIL import Image
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from timeit import default_timer as timer
# è®¾å¤‡è‡ªåŠ¨é€‰æ‹©
device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")


# --------------- SQLiteæ•°æ®åº“ç®¡ç† ---------------
class DogDB:
    _instance = None
    
    def __init__(self, db_path="data/dog_classifier.db"):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’Œè¡¨ç»“æ„"""
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(exist_ok=True)
        self.conn = None
        self.connect()
        self.create_tables()
    
    @classmethod
    def get_instance(cls, db_path="data/dog_classifier.db"):
        """å•ä¾‹æ¨¡å¼è·å–æ•°æ®åº“å®ä¾‹"""
        if cls._instance is None:
            cls._instance = cls(db_path)
        return cls._instance
    
    def connect(self):
        """è¿æ¥åˆ°SQLiteæ•°æ®åº“"""
        try:
            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
            self.conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸å½¢å¼çš„ç»“æœ
            print(f"æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {self.db_path}")
            return True
        except sqlite3.Error as e:
            print(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
            return False
    
    def create_tables(self):
        """åˆ›å»ºå¿…è¦çš„è¡¨ç»“æ„"""
        try:
            cursor = self.conn.cursor()
            
            # æ¨¡å‹ä¿¡æ¯è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS models (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT NOT NULL,
                num_classes INTEGER NOT NULL,
                accuracy REAL NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_used TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            ''')
            
            # ç±»åˆ«åç§°è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS class_names (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_id INTEGER NOT NULL,
                class_id INTEGER NOT NULL,
                class_name TEXT NOT NULL,
                FOREIGN KEY (model_id) REFERENCES models (id)
            )
            ''')
            
            # é¢„æµ‹å†å²è®°å½•è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS prediction_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                image_path TEXT NOT NULL,
                prediction TEXT NOT NULL,
                confidence REAL NOT NULL,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            ''')
            
            # è®­ç»ƒè®°å½•è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS training_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_id INTEGER NOT NULL,
                epoch INTEGER NOT NULL,
                train_loss REAL NOT NULL,
                train_accuracy REAL NOT NULL,
                test_accuracy REAL NOT NULL,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (model_id) REFERENCES models (id)
            )
            ''')
            
            self.conn.commit()
            print("æ•°æ®åº“è¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")
            return True
        except sqlite3.Error as e:
            print(f"åˆ›å»ºè¡¨ç»“æ„é”™è¯¯: {e}")
            return False
    
    def execute(self, query, params=(), commit=True):
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        if not self.conn:
            if not self.connect():
                return None
                
        try:
            cursor = self.conn.cursor()
            cursor.execute(query, params)
            
            if commit:
                self.conn.commit()
                
            return cursor
        except sqlite3.Error as e:
            print(f"SQLæ‰§è¡Œé”™è¯¯: {e}")
            print(f"æŸ¥è¯¢: {query}")
            print(f"å‚æ•°: {params}")
            return None
    
    def save_model_info(self, model_name, num_classes, accuracy, class_names):
        """ä¿å­˜æ¨¡å‹ä¿¡æ¯åˆ°æ•°æ®åº“"""
        try:
            # æ’å…¥æˆ–æ›´æ–°æ¨¡å‹ä¿¡æ¯
            cursor = self.execute(
                "INSERT INTO models (model_name, num_classes, accuracy) VALUES (?, ?, ?)",
                (model_name, num_classes, accuracy)
            )
            model_id = cursor.lastrowid
            
            # æ’å…¥ç±»åˆ«åç§°
            for i, class_name in enumerate(class_names):
                self.execute(
                    "INSERT INTO class_names (model_id, class_id, class_name) VALUES (?, ?, ?)",
                    (model_id, i, class_name)
                )
            
            print(f"æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜åˆ°æ•°æ®åº“, ID: {model_id}")
            return model_id
        except Exception as e:
            print(f"ä¿å­˜æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def save_prediction(self, image_path, prediction, confidence):
        """ä¿å­˜é¢„æµ‹è®°å½•"""
        try:
            self.execute(
                "INSERT INTO prediction_history (image_path, prediction, confidence) VALUES (?, ?, ?)",
                (str(image_path), prediction, confidence)
            )
            return True
        except Exception as e:
            print(f"ä¿å­˜é¢„æµ‹è®°å½•å¤±è´¥: {e}")
            return False
    
    def save_training_record(self, model_id, epoch, train_loss, train_accuracy, test_accuracy):
        """ä¿å­˜è®­ç»ƒè®°å½•"""
        try:
            self.execute(
                "INSERT INTO training_records (model_id, epoch, train_loss, train_accuracy, test_accuracy) VALUES (?, ?, ?, ?, ?)",
                (model_id, epoch, train_loss, train_accuracy, test_accuracy)
            )
            return True
        except Exception as e:
            print(f"ä¿å­˜è®­ç»ƒè®°å½•å¤±è´¥: {e}")
            return False
            
    def get_prediction_history(self, limit=10):
        """è·å–æœ€è¿‘çš„é¢„æµ‹å†å²"""
        try:
            cursor = self.execute(
                "SELECT * FROM prediction_history ORDER BY timestamp DESC LIMIT ?",
                (limit,)
            )
            return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            print(f"è·å–é¢„æµ‹å†å²å¤±è´¥: {e}")
            return []
    
    def get_class_names(self, model_id):
        """ä»æ•°æ®åº“è·å–ç±»åˆ«åç§°"""
        try:
            cursor = self.execute(
                "SELECT class_id, class_name FROM class_names WHERE model_id = ? ORDER BY class_id",
                (model_id,)
            )
            return [row['class_name'] for row in cursor.fetchall()]
        except Exception as e:
            print(f"è·å–ç±»åˆ«åç§°å¤±è´¥: {e}")
            return []
    
    def get_latest_model_id(self):
        """è·å–æœ€æ–°çš„æ¨¡å‹ID"""
        try:
            cursor = self.execute("SELECT id FROM models ORDER BY created_at DESC LIMIT 1")
            result = cursor.fetchone()
            return result['id'] if result else None
        except Exception as e:
            print(f"è·å–æœ€æ–°æ¨¡å‹IDå¤±è´¥: {e}")
            return None
    
    def update_model_usage(self, model_id):
        """æ›´æ–°æ¨¡å‹æœ€åä½¿ç”¨æ—¶é—´"""
        try:
            self.execute(
                "UPDATE models SET last_used = CURRENT_TIMESTAMP WHERE id = ?",
                (model_id,)
            )
            return True
        except Exception as e:
            print(f"æ›´æ–°æ¨¡å‹ä½¿ç”¨æ—¶é—´å¤±è´¥: {e}")
            return False
            
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            self.conn = None


# --------------- æ¨¡å‹å®šä¹‰ ---------------
class DogClassifierModel(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        # åŠ è½½é¢„è®­ç»ƒçš„ResNet18
        self.resnet = models.resnet18(pretrained=True)
        
        # å†»ç»“å¤§éƒ¨åˆ†å±‚
        for param in list(self.resnet.parameters())[:-4]:
            param.requires_grad = False
            
        # ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚
        num_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        return self.resnet(x)

# --------------- è®­ç»ƒåŠŸèƒ½ ---------------
def calculate_accuracy(model, data_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return correct / total

def train():
    """è®­ç»ƒå…¥å£å‡½æ•°"""
    data_path = Path("data/god")
    model_path = Path("models/resnet18_dog_classifier.pth")

    # æ•°æ®åŠ è½½å’Œå¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),  # ResNetéœ€è¦224x224çš„è¾“å…¥
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(15),
        transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # åŠ è½½æ•°æ®é›†
    train_data = datasets.ImageFolder(root=data_path / "train", transform=train_transform)
    test_data = datasets.ImageFolder(root=data_path / "test", transform=test_transform)

    # ä¿å­˜ç±»åˆ«åç§°åˆ°æ–‡ä»¶ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
    model_path.parent.mkdir(exist_ok=True)
    with open(model_path.parent / "class_names.txt", "w", encoding='utf-8') as f:
        f.write("\n".join(train_data.classes))

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_data,
        batch_size=16,  # è¾ƒå°çš„batch_size
        shuffle=True,
        num_workers=2,
        pin_memory=True
    )

    test_loader = DataLoader(
        test_data,
        batch_size=16,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )

    # åˆå§‹åŒ–æ¨¡å‹
    model = DogClassifierModel(len(train_data.classes)).to(device)
    
    # ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡
    params_to_update = []
    params_to_update_names = []
    
    for name, param in model.named_parameters():
        if param.requires_grad:
            params_to_update.append(param)
            params_to_update_names.append(name)

    # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦
    optimizer = torch.optim.AdamW(params_to_update, lr=0.001, weight_decay=0.01)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.1, patience=3, verbose=True
    )
    loss_fn = nn.CrossEntropyLoss()

    # åˆå§‹åŒ–æ•°æ®åº“
    db = DogDB.get_instance()
    
    # è®­ç»ƒå¾ªç¯
    best_test_acc = 0.0
    patience = 7  # æ—©åœè€å¿ƒå€¼
    patience_counter = 0
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_data)} | æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_data)}")
    print("-" * 60)

    for epoch in range(50):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        # è®­ç»ƒé˜¶æ®µ
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()

            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        epoch_loss = running_loss / len(train_loader.dataset)
        train_acc = correct / total

        # è¯„ä¼°é˜¶æ®µ
        test_acc = calculate_accuracy(model, test_loader, device)
        
        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step(test_acc)
        
        # ä¿å­˜è®­ç»ƒè®°å½•åˆ°æ•°æ®åº“
        model_id = db.get_latest_model_id()
        if not model_id:
            # é¦–æ¬¡åˆ›å»ºæ¨¡å‹è®°å½•
            model_id = db.save_model_info(
                model_name="resnet18_dog_classifier",
                num_classes=len(train_data.classes),
                accuracy=test_acc,
                class_names=train_data.classes
            )
        
        # ä¿å­˜å½“å‰è½®æ¬¡çš„è®­ç»ƒè®°å½•
        db.save_training_record(
            model_id=model_id,
            epoch=epoch + 1,
            train_loss=epoch_loss,
            train_accuracy=train_acc,
            test_accuracy=test_acc
        )

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_acc > best_test_acc:
            best_test_acc = test_acc
            torch.save(model.state_dict(), model_path)
            patience_counter = 0
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„æ¨¡å‹å‡†ç¡®ç‡
            db.execute(
                "UPDATE models SET accuracy = ? WHERE id = ?",
                (best_test_acc, model_id)
            )
        else:
            patience_counter += 1

        # æ‰“å°è®­ç»ƒä¿¡æ¯
        print(f"Epoch {epoch + 1}/50")
        print(f"è®­ç»ƒæŸå¤±: {epoch_loss:.4f} | è®­ç»ƒå‡†ç¡®ç‡: {train_acc * 100:.2f}%")
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {test_acc * 100:.2f}%")
        print("-" * 60)

        # æ—©åœæ£€æŸ¥
        if patience_counter >= patience:
            print("å‡†ç¡®ç‡å·²ç»åœæ­¢æå‡ï¼Œæå‰ç»“æŸè®­ç»ƒã€‚")
            break

    print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æµ‹è¯•å‡†ç¡®ç‡ï¼š{best_test_acc * 100:.2f}%")


# --------------- é¢„æµ‹åŠŸèƒ½ï¼ˆAPIä¸“ç”¨ï¼‰---------------
class DogClassifier:
    _instance = None

    def __init__(self):
        self.model = None
        self.class_names = []
        self.db = DogDB.get_instance()
        self.load_model()

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        model_path = Path("models/resnet18_dog_classifier.pth")
        if not model_path.exists():
            raise FileNotFoundError("è¯·å…ˆè¿è¡Œè®­ç»ƒç”Ÿæˆæ¨¡å‹æ–‡ä»¶")

        # ä¼˜å…ˆä»æ–‡ä»¶åŠ è½½ç±»åˆ«åç§°ï¼ˆå…¼å®¹ä¼ ç»Ÿæ–¹å¼ï¼‰
        class_names_file = model_path.parent / "class_names.txt"
        if class_names_file.exists():
            with open(class_names_file, encoding='utf-8') as f:
                self.class_names = f.read().splitlines()
        else:
            # å°è¯•ä»æ•°æ®åº“åŠ è½½
            model_id = self.db.get_latest_model_id()
            if model_id:
                self.class_names = self.db.get_class_names(model_id)
                if not self.class_names:
                    raise ValueError("æ— æ³•ä»æ•°æ®åº“åŠ è½½ç±»åˆ«åç§°")
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æ¨¡å‹ä¿¡æ¯")

        self.model = DogClassifierModel(len(self.class_names)).to(device)
        self.model.load_state_dict(torch.load(model_path, map_location=device))
        self.model.eval()
        
        # æ›´æ–°æ¨¡å‹ä½¿ç”¨æ—¶é—´
        model_id = self.db.get_latest_model_id()
        if model_id:
            self.db.update_model_usage(model_id)

    def predict(self, image_path: str) -> dict:
        """æ‰§è¡Œå•å¼ å›¾ç‰‡é¢„æµ‹"""
        try:
            image = Image.open(image_path).convert("RGB")
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            tensor = transform(image).unsqueeze(0).to(device)

            with torch.no_grad():
                preds = torch.nn.functional.softmax(self.model(tensor), dim=1)

            conf, idx = torch.max(preds, dim=1)
            prediction = self.class_names[idx.item()]
            confidence = round(conf.item(), 4)
            
            # ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“
            self.db.save_prediction(image_path, prediction, confidence)
            
            return {
                "class": prediction,
                "confidence": confidence,
                "status": "success"
            }
        except Exception as e:
            return {
                "error": str(e),
                "status": "error"
            }
    
    def get_prediction_history(self, limit=10):
        """è·å–é¢„æµ‹å†å²è®°å½•"""
        return self.db.get_prediction_history(limit)


# --------------- ä¸»ç¨‹åºå…¥å£ ---------------
if __name__ == "__main__":
    multiprocessing.freeze_support()
    
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    Path("data").mkdir(exist_ok=True)
    Path("models").mkdir(exist_ok=True)

    # è‡ªåŠ¨è®­ç»ƒé€»è¾‘
    if not Path("models/resnet18_dog_classifier.pth").exists():
        print("ğŸš€ æ£€æµ‹åˆ°æœªè®­ç»ƒæ¨¡å‹ï¼Œå¼€å§‹è®­ç»ƒ...")
        start_time = timer()
        train()
        end_time = timer()
        print(f"æ€»è®­ç»ƒæ—¶é—´ï¼š{end_time-start_time:.2f}ç§’")
    else:
        print("âœ… æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡è®­ç»ƒ")

    # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¦‚æœè¿˜æœªåˆå§‹åŒ–ï¼‰
    db = DogDB.get_instance()
    
    # ç¤ºä¾‹é¢„æµ‹
    classifier = DogClassifier.get_instance()
    
    # å¦‚æœæœ‰myq.jpgæ–‡ä»¶ï¼Œè¿›è¡Œé¢„æµ‹æµ‹è¯•
    test_image = Path("data/myq.jpg")
    if test_image.exists():
        result = classifier.predict(str(test_image))
        print("æµ‹è¯•é¢„æµ‹ç»“æœ:", result)
        
        # æ˜¾ç¤ºæœ€è¿‘çš„é¢„æµ‹å†å²
        history = classifier.get_prediction_history(5)
        if history:
            print("\næœ€è¿‘5æ¡é¢„æµ‹å†å²:")
            for record in history:
                print(f"- {record['prediction']} (ç½®ä¿¡åº¦: {record['confidence']}) - {record['timestamp']}")
    
    # å…³é—­æ•°æ®åº“è¿æ¥
    db.close()






